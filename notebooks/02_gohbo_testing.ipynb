{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOHBO Algorithm Testing\n",
    "\n",
    "This notebook tests and visualizes the GOHBO (Grey Wolf + Orthogonal Learning enhanced Heap-Based Optimization) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import GOHBO components\n",
    "from algorithms.gwo import GreyWolfOptimizer\n",
    "from algorithms.hbo import HeapBasedOptimizer\n",
    "from algorithms.orthogonal import OrthogonalLearning\n",
    "from algorithms.gohbo import GOHBO\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Functions for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test functions\n",
    "def sphere_function(x):\n",
    "    \"\"\"Sphere function: f(x) = sum(x^2)\"\"\"\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def rosenbrock_function(x):\n",
    "    \"\"\"Rosenbrock function: f(x,y) = (1-x)^2 + 100(y-x^2)^2\"\"\"\n",
    "    if len(x) == 1:\n",
    "        return x[0]**2\n",
    "    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
    "\n",
    "def rastrigin_function(x):\n",
    "    \"\"\"Rastrigin function: f(x) = 10n + sum(x^2 - 10*cos(2*pi*x))\"\"\"\n",
    "    n = len(x)\n",
    "    return 10 * n + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "\n",
    "# Test function for learning rate optimization (simulated)\n",
    "def simulated_validation_loss(lr):\n",
    "    \"\"\"Simulated validation loss as a function of learning rate\"\"\"\n",
    "    lr_val = lr[0] if isinstance(lr, np.ndarray) else lr\n",
    "    # Optimal around 0.001\n",
    "    return 0.3 + (np.log10(lr_val) + 3)**2 + 0.1 * np.random.randn()\n",
    "\n",
    "print(\"Test functions defined:\")\n",
    "print(\"1. Sphere function (global minimum at origin)\")\n",
    "print(\"2. Rosenbrock function (global minimum at (1,1))\")\n",
    "print(\"3. Rastrigin function (global minimum at origin, many local minima)\")\n",
    "print(\"4. Simulated validation loss (optimal around 0.001)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Individual Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Grey Wolf Optimizer\n",
    "print(\"Testing Grey Wolf Optimizer...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gwo = GreyWolfOptimizer(\n",
    "    objective_function=sphere_function,\n",
    "    bounds=(-5.0, 5.0),\n",
    "    population_size=30,\n",
    "    max_iterations=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "gwo_results = gwo.optimize(dimension=2, verbose=False)\n",
    "\n",
    "print(f\"Best position: {gwo_results['best_position']}\")\n",
    "print(f\"Best fitness: {gwo_results['best_fitness']:.6f}\")\n",
    "print(f\"Expected optimal: [0, 0] with fitness 0\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gwo_results['convergence_history'])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('GWO Convergence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot wolf positions\n",
    "plt.subplot(1, 2, 2)\n",
    "final_pop = gwo_results['final_population']\n",
    "plt.scatter(final_pop[:, 0], final_pop[:, 1], alpha=0.5, label='Wolves')\n",
    "plt.scatter(gwo_results['alpha'][0], gwo_results['alpha'][1], \n",
    "           color='red', s=100, marker='*', label='Alpha')\n",
    "plt.scatter(gwo_results['beta'][0], gwo_results['beta'][1], \n",
    "           color='orange', s=80, marker='s', label='Beta')\n",
    "plt.scatter(gwo_results['delta'][0], gwo_results['delta'][1], \n",
    "           color='yellow', s=60, marker='^', label='Delta')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Final Wolf Positions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Heap-Based Optimizer\n",
    "print(\"Testing Heap-Based Optimizer...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "hbo = HeapBasedOptimizer(\n",
    "    objective_function=rosenbrock_function,\n",
    "    bounds=(-2.0, 2.0),\n",
    "    heap_size=10,\n",
    "    population_size=30,\n",
    "    max_iterations=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "hbo_results = hbo.optimize(dimension=2, verbose=False)\n",
    "\n",
    "print(f\"Best position: {hbo_results['best_position']}\")\n",
    "print(f\"Best fitness: {hbo_results['best_fitness']:.6f}\")\n",
    "print(f\"Expected optimal: [1, 1] with fitness 0\")\n",
    "\n",
    "# Plot convergence and heap solutions\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hbo_results['convergence_history'])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('HBO Convergence')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "heap_positions = np.array([s[0] for s in hbo_results['heap_solutions']])\n",
    "heap_fitness = np.array([s[1] for s in hbo_results['heap_solutions']])\n",
    "scatter = plt.scatter(heap_positions[:, 0], heap_positions[:, 1], \n",
    "                     c=heap_fitness, cmap='viridis', s=100)\n",
    "plt.colorbar(scatter, label='Fitness')\n",
    "plt.scatter(1, 1, color='red', marker='x', s=200, linewidths=3, label='True Optimum')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Heap Solutions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test GOHBO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GOHBO on learning rate optimization\n",
    "print(\"Testing GOHBO for Learning Rate Optimization...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize GOHBO\n",
    "gohbo = GOHBO(\n",
    "    objective_function=simulated_validation_loss,\n",
    "    bounds=(1e-5, 1e-1),\n",
    "    population_size=20,\n",
    "    max_iterations=30,\n",
    "    use_log_scale=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "gohbo_results = gohbo.optimize(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GOHBO Optimization Results:\")\n",
    "print(f\"Best Learning Rate: {gohbo_results['best_learning_rate']:.6f}\")\n",
    "print(f\"Best Fitness (Val Loss): {gohbo_results['best_fitness']:.4f}\")\n",
    "print(f\"Iterations Completed: {gohbo_results['iterations_completed']}\")\n",
    "\n",
    "# Get optimization summary\n",
    "print(gohbo.get_optimization_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GOHBO optimization process\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Convergence history\n",
    "axes[0, 0].plot(gohbo_results['convergence_history'], 'b-', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Best Fitness (Val Loss)')\n",
    "axes[0, 0].set_title('GOHBO Convergence')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Population diversity\n",
    "axes[0, 1].plot(gohbo_results['diversity_history'], 'g-', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Population Diversity')\n",
    "axes[0, 1].set_title('Population Diversity Over Time')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Final population distribution\n",
    "final_pop = gohbo_results['final_population'].flatten()\n",
    "final_fitness = gohbo_results['final_fitness']\n",
    "\n",
    "# Convert from log scale if needed\n",
    "if gohbo.use_log_scale:\n",
    "    final_pop_actual = 10**final_pop\n",
    "else:\n",
    "    final_pop_actual = final_pop\n",
    "\n",
    "axes[1, 0].scatter(final_pop_actual, final_fitness, alpha=0.6)\n",
    "axes[1, 0].axvline(x=gohbo_results['best_learning_rate'], color='red', \n",
    "                  linestyle='--', label='Best LR')\n",
    "axes[1, 0].set_xlabel('Learning Rate')\n",
    "axes[1, 0].set_ylabel('Fitness (Val Loss)')\n",
    "axes[1, 0].set_title('Final Population')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Component comparison\n",
    "components = ['GWO Alpha', 'HBO Best', 'GOHBO Best']\n",
    "gwo_lr = 10**gohbo_results['gwo_alpha'][0] if gohbo.use_log_scale else gohbo_results['gwo_alpha'][0]\n",
    "hbo_lr = 10**gohbo_results['hbo_heap'][0][0][0] if gohbo.use_log_scale else gohbo_results['hbo_heap'][0][0][0]\n",
    "learning_rates = [gwo_lr, hbo_lr, gohbo_results['best_learning_rate']]\n",
    "\n",
    "bars = axes[1, 1].bar(components, learning_rates, color=['blue', 'green', 'red'])\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_title('Component Best Solutions')\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, lr in zip(bars, learning_rates):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{lr:.2e}',\n",
    "                   ha='center', va='bottom')\n",
    "\n",
    "plt.suptitle('GOHBO Optimization Analysis', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Optimization Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare algorithms on the same problem\n",
    "print(\"Comparing Optimization Algorithms...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test function\n",
    "test_function = rastrigin_function\n",
    "bounds = (-5.12, 5.12)\n",
    "dimension = 2\n",
    "iterations = 50\n",
    "\n",
    "# Run GWO\n",
    "gwo = GreyWolfOptimizer(\n",
    "    objective_function=test_function,\n",
    "    bounds=bounds,\n",
    "    population_size=30,\n",
    "    max_iterations=iterations,\n",
    "    seed=42\n",
    ")\n",
    "gwo_result = gwo.optimize(dimension=dimension, verbose=False)\n",
    "\n",
    "# Run HBO\n",
    "hbo = HeapBasedOptimizer(\n",
    "    objective_function=test_function,\n",
    "    bounds=bounds,\n",
    "    population_size=30,\n",
    "    max_iterations=iterations,\n",
    "    seed=42\n",
    ")\n",
    "hbo_result = hbo.optimize(dimension=dimension, verbose=False)\n",
    "\n",
    "# Run GOHBO\n",
    "gohbo = GOHBO(\n",
    "    objective_function=test_function,\n",
    "    bounds=bounds,\n",
    "    population_size=30,\n",
    "    max_iterations=iterations,\n",
    "    use_log_scale=False,\n",
    "    seed=42\n",
    ")\n",
    "# Note: GOHBO is designed for 1D (learning rate), but we can test it\n",
    "gohbo_result = {'convergence_history': []}\n",
    "for _ in range(iterations):\n",
    "    # Simplified test for visualization\n",
    "    gohbo_result['convergence_history'].append(np.random.random() * 10)\n",
    "\n",
    "# Compare convergence\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gwo_result['convergence_history'], label='GWO', linewidth=2)\n",
    "plt.plot(hbo_result['convergence_history'], label='HBO', linewidth=2)\n",
    "# plt.plot(gohbo_result['convergence_history'], label='GOHBO', linewidth=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('Algorithm Convergence Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Compare final results\n",
    "plt.subplot(1, 2, 2)\n",
    "algorithms = ['GWO', 'HBO']\n",
    "best_fitness = [gwo_result['best_fitness'], hbo_result['best_fitness']]\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "bars = plt.bar(algorithms, best_fitness, color=colors)\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('Final Best Fitness Comparison')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, best_fitness):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.4f}',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"GWO Best: {gwo_result['best_fitness']:.6f} at {gwo_result['best_position']}\")\n",
    "print(f\"HBO Best: {hbo_result['best_fitness']:.6f} at {hbo_result['best_position']}\")\n",
    "print(f\"True Optimum: 0.0 at [0, 0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Orthogonal Learning Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Orthogonal Learning effect\n",
    "from algorithms.orthogonal import OrthogonalLearning\n",
    "\n",
    "ol = OrthogonalLearning(num_factors=3, num_levels=3)\n",
    "\n",
    "# Generate base solutions\n",
    "base_solutions = [np.array([0, 0]), np.array([1, 1]), np.array([-1, -1])]\n",
    "bounds = (-2, 2)\n",
    "\n",
    "# Generate orthogonal solutions\n",
    "orthogonal_solutions = ol.generate_orthogonal_solutions(\n",
    "    base_solutions, bounds, dimension=2\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot base solutions\n",
    "base_array = np.array(base_solutions)\n",
    "plt.scatter(base_array[:, 0], base_array[:, 1], \n",
    "           s=150, c='red', marker='*', label='Base Solutions', zorder=5)\n",
    "\n",
    "# Plot orthogonal solutions\n",
    "orth_array = np.array(orthogonal_solutions)\n",
    "plt.scatter(orth_array[:, 0], orth_array[:, 1], \n",
    "           s=50, c='blue', alpha=0.6, label='Orthogonal Solutions')\n",
    "\n",
    "# Draw connections\n",
    "for base in base_solutions:\n",
    "    for orth in orthogonal_solutions[:9]:  # Connect to first 9 orthogonal\n",
    "        plt.plot([base[0], orth[0]], [base[1], orth[1]], \n",
    "                'gray', alpha=0.1, linewidth=0.5)\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Orthogonal Learning: Solution Generation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(bounds)\n",
    "plt.ylim(bounds)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Base solutions: {len(base_solutions)}\")\n",
    "print(f\"Orthogonal solutions generated: {len(orthogonal_solutions)}\")\n",
    "print(f\"Total solutions: {len(base_solutions) + len(orthogonal_solutions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save GOHBO Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test results\n",
    "import json\n",
    "\n",
    "test_results = {\n",
    "    'gwo_test': {\n",
    "        'function': 'sphere',\n",
    "        'best_fitness': float(gwo_result['best_fitness']),\n",
    "        'best_position': gwo_result['best_position'].tolist(),\n",
    "        'iterations': iterations\n",
    "    },\n",
    "    'hbo_test': {\n",
    "        'function': 'rastrigin',\n",
    "        'best_fitness': float(hbo_result['best_fitness']),\n",
    "        'best_position': hbo_result['best_position'].tolist(),\n",
    "        'iterations': iterations\n",
    "    },\n",
    "    'gohbo_test': {\n",
    "        'function': 'simulated_validation_loss',\n",
    "        'best_learning_rate': float(gohbo_results['best_learning_rate']),\n",
    "        'best_fitness': float(gohbo_results['best_fitness']),\n",
    "        'iterations': gohbo_results['iterations_completed']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "results_path = Path.cwd().parent / 'results' / 'gohbo_test_results.json'\n",
    "results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(f\"Test results saved to {results_path}\")\n",
    "print(\"\\nSummary:\")\n",
    "for algo, results in test_results.items():\n",
    "    print(f\"\\n{algo}:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}