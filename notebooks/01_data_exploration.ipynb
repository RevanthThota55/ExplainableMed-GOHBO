{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Dataset Exploration\n",
    "\n",
    "This notebook explores the three medical imaging datasets:\n",
    "- Brain Tumor MRI Classification\n",
    "- Chest X-Ray Pneumonia Detection\n",
    "- Colorectal Cancer Histopathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import project modules\n",
    "from config import get_config\n",
    "from datasets.brain_tumor import BrainTumorDataset\n",
    "from datasets.chest_xray import ChestXRayDataset\n",
    "from datasets.colorectal import ColorectalDataset\n",
    "from utils.visualization import visualize_batch\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Brain Tumor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Brain Tumor dataset\n",
    "config_brain = get_config('brain_tumor')\n",
    "brain_dataset_path = config_brain['dataset']['data_path']\n",
    "\n",
    "# Check if dataset exists\n",
    "if brain_dataset_path.exists():\n",
    "    # Load train dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    brain_train = BrainTumorDataset(\n",
    "        root_dir=brain_dataset_path,\n",
    "        split='train',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {config_brain['dataset']['name']}\")\n",
    "    print(f\"Number of classes: {config_brain['dataset']['num_classes']}\")\n",
    "    print(f\"Classes: {', '.join(brain_train.classes)}\")\n",
    "    print(f\"Training samples: {len(brain_train)}\")\n",
    "    \n",
    "    # Get class distribution\n",
    "    distribution = brain_train.get_class_distribution()\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for class_name, count in distribution.items():\n",
    "        print(f\"  {class_name}: {count}\")\n",
    "else:\n",
    "    print(f\"Brain tumor dataset not found at {brain_dataset_path}\")\n",
    "    print(\"Run 'python src/datasets/download_datasets.py' to download the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from brain tumor dataset\n",
    "if 'brain_train' in locals():\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    brain_loader = DataLoader(brain_train, batch_size=16, shuffle=True)\n",
    "    visualize_batch(brain_loader, brain_train.classes, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution for brain tumor dataset\n",
    "if 'brain_train' in locals():\n",
    "    distribution = brain_train.get_class_distribution()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    classes = list(distribution.keys())\n",
    "    counts = list(distribution.values())\n",
    "    \n",
    "    bars = plt.bar(classes, counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    plt.xlabel('Tumor Type')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Brain Tumor Dataset - Class Distribution')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{count}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chest X-Ray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Chest X-Ray dataset\n",
    "config_chest = get_config('chest_xray')\n",
    "chest_dataset_path = config_chest['dataset']['data_path']\n",
    "\n",
    "if chest_dataset_path.exists():\n",
    "    chest_train = ChestXRayDataset(\n",
    "        root_dir=chest_dataset_path,\n",
    "        split='train',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {config_chest['dataset']['name']}\")\n",
    "    print(f\"Number of classes: {config_chest['dataset']['num_classes']}\")\n",
    "    print(f\"Classes: {', '.join(chest_train.classes)}\")\n",
    "    print(f\"Training samples: {len(chest_train)}\")\n",
    "    \n",
    "    # Get class distribution\n",
    "    distribution = chest_train.get_class_distribution()\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for class_name, count in distribution.items():\n",
    "        print(f\"  {class_name}: {count}\")\n",
    "    \n",
    "    # Check for pneumonia subtypes\n",
    "    subtypes = chest_train.get_pneumonia_subtypes()\n",
    "    print(\"\\nPneumonia subtypes:\")\n",
    "    for subtype, indices in subtypes.items():\n",
    "        print(f\"  {subtype}: {len(indices)} samples\")\n",
    "else:\n",
    "    print(f\"Chest X-ray dataset not found at {chest_dataset_path}\")\n",
    "    print(\"Run 'python src/datasets/download_datasets.py' to download the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample chest X-rays\n",
    "if 'chest_train' in locals():\n",
    "    chest_loader = DataLoader(chest_train, batch_size=16, shuffle=True)\n",
    "    visualize_batch(chest_loader, chest_train.classes, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Colorectal Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Colorectal dataset\n",
    "config_colorectal = get_config('colorectal')\n",
    "colorectal_dataset_path = config_colorectal['dataset']['data_path']\n",
    "\n",
    "if colorectal_dataset_path.exists():\n",
    "    colorectal_train = ColorectalDataset(\n",
    "        root_dir=colorectal_dataset_path,\n",
    "        split='train',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {config_colorectal['dataset']['name']}\")\n",
    "    print(f\"Number of classes: {config_colorectal['dataset']['num_classes']}\")\n",
    "    print(f\"Classes: {', '.join(colorectal_train.classes)}\")\n",
    "    print(f\"Training samples: {len(colorectal_train)}\")\n",
    "    \n",
    "    # Get class distribution\n",
    "    distribution = colorectal_train.get_class_distribution()\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for class_name, count in distribution.items():\n",
    "        desc = colorectal_train.class_descriptions[class_name]\n",
    "        print(f\"  {class_name} ({desc}): {count}\")\n",
    "    \n",
    "    # Get tissue type distribution\n",
    "    tissue_dist = colorectal_train.get_cancer_vs_normal_distribution()\n",
    "    print(\"\\nTissue type distribution:\")\n",
    "    for tissue_type, count in tissue_dist.items():\n",
    "        print(f\"  {tissue_type}: {count}\")\n",
    "else:\n",
    "    print(f\"Colorectal dataset not found at {colorectal_dataset_path}\")\n",
    "    print(\"Run 'python src/datasets/download_datasets.py' to download the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize colorectal tissue samples\n",
    "if 'colorectal_train' in locals():\n",
    "    colorectal_loader = DataLoader(colorectal_train, batch_size=16, shuffle=True)\n",
    "    visualize_batch(colorectal_loader, colorectal_train.classes, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare datasets\n",
    "datasets_info = []\n",
    "\n",
    "if 'brain_train' in locals():\n",
    "    datasets_info.append({\n",
    "        'Dataset': 'Brain Tumor',\n",
    "        'Classes': len(brain_train.classes),\n",
    "        'Train Samples': len(brain_train),\n",
    "        'Image Type': 'MRI',\n",
    "        'Task': 'Multi-class'\n",
    "    })\n",
    "\n",
    "if 'chest_train' in locals():\n",
    "    datasets_info.append({\n",
    "        'Dataset': 'Chest X-Ray',\n",
    "        'Classes': len(chest_train.classes),\n",
    "        'Train Samples': len(chest_train),\n",
    "        'Image Type': 'X-Ray',\n",
    "        'Task': 'Binary'\n",
    "    })\n",
    "\n",
    "if 'colorectal_train' in locals():\n",
    "    datasets_info.append({\n",
    "        'Dataset': 'Colorectal',\n",
    "        'Classes': len(colorectal_train.classes),\n",
    "        'Train Samples': len(colorectal_train),\n",
    "        'Image Type': 'Microscopy',\n",
    "        'Task': 'Multi-class'\n",
    "    })\n",
    "\n",
    "if datasets_info:\n",
    "    df = pd.DataFrame(datasets_info)\n",
    "    print(\"Dataset Comparison:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Number of classes\n",
    "    axes[0].bar(df['Dataset'], df['Classes'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    axes[0].set_ylabel('Number of Classes')\n",
    "    axes[0].set_title('Classes per Dataset')\n",
    "    \n",
    "    # Plot 2: Number of samples\n",
    "    axes[1].bar(df['Dataset'], df['Train Samples'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    axes[1].set_ylabel('Number of Training Samples')\n",
    "    axes[1].set_title('Training Samples per Dataset')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No datasets loaded. Please download the datasets first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate data augmentation\n",
    "if 'brain_train' in locals():\n",
    "    # Get a single image\n",
    "    image, label = brain_train[0]\n",
    "    \n",
    "    # Define augmentation transforms\n",
    "    augmentations = [\n",
    "        ('Original', transforms.Compose([transforms.Resize((224, 224))])),\n",
    "        ('Horizontal Flip', transforms.Compose([transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(p=1.0)])),\n",
    "        ('Rotation', transforms.Compose([transforms.Resize((224, 224)), transforms.RandomRotation(15)])),\n",
    "        ('Color Jitter', transforms.Compose([transforms.Resize((224, 224)), transforms.ColorJitter(0.2, 0.2, 0.2, 0.1)])),\n",
    "        ('Random Affine', transforms.Compose([transforms.Resize((224, 224)), transforms.RandomAffine(10, translate=(0.1, 0.1))])),\n",
    "        ('Gaussian Blur', transforms.Compose([transforms.Resize((224, 224)), transforms.GaussianBlur(3)])),\n",
    "    ]\n",
    "    \n",
    "    # Apply augmentations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Load original image\n",
    "    orig_img = Image.open(brain_train.image_paths[0]).convert('RGB')\n",
    "    \n",
    "    for i, (name, aug) in enumerate(augmentations):\n",
    "        aug_img = aug(orig_img)\n",
    "        if isinstance(aug_img, torch.Tensor):\n",
    "            aug_img = aug_img.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        axes[i].imshow(aug_img)\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Data Augmentation Examples - {brain_train.classes[label]}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset statistics to file\n",
    "import json\n",
    "\n",
    "stats = {}\n",
    "\n",
    "if 'brain_train' in locals():\n",
    "    stats['brain_tumor'] = {\n",
    "        'num_classes': len(brain_train.classes),\n",
    "        'classes': brain_train.classes,\n",
    "        'train_samples': len(brain_train),\n",
    "        'distribution': brain_train.get_class_distribution()\n",
    "    }\n",
    "\n",
    "if 'chest_train' in locals():\n",
    "    stats['chest_xray'] = {\n",
    "        'num_classes': len(chest_train.classes),\n",
    "        'classes': chest_train.classes,\n",
    "        'train_samples': len(chest_train),\n",
    "        'distribution': chest_train.get_class_distribution()\n",
    "    }\n",
    "\n",
    "if 'colorectal_train' in locals():\n",
    "    stats['colorectal'] = {\n",
    "        'num_classes': len(colorectal_train.classes),\n",
    "        'classes': colorectal_train.classes,\n",
    "        'train_samples': len(colorectal_train),\n",
    "        'distribution': colorectal_train.get_class_distribution()\n",
    "    }\n",
    "\n",
    "if stats:\n",
    "    stats_path = Path.cwd().parent / 'results' / 'dataset_statistics.json'\n",
    "    stats_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(stats_path, 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    print(f\"Dataset statistics saved to {stats_path}\")\n",
    "else:\n",
    "    print(\"No datasets loaded to save statistics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}